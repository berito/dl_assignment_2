{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["408a93c2","fARq-0PfLuHJ","OnxfYYKYrWea","PhddOZXMIkvv","uBVVLf86I7En","4suWT0ikcF6F"],"gpuType":"T4","provenance":[]},"gpuClass":"standard","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Download  Dataset From Kaggle and Import Libraries","metadata":{"id":"kUwy5de-c1A8"}},{"cell_type":"code","source":"# download gtsrb traffic sign dataset from kaggle\n!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign","metadata":{"id":"xJavD7IKiRNO","outputId":"e28103f8-e49e-415b-947e-adea830e5ed4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create dataset directory and unzip the downloaded dataset\n!mkdir dataset\n!unzip -q gtsrb-german-traffic-sign.zip -d /kaggle/working/dataset","metadata":{"execution":{"iopub.execute_input":"2024-07-03T11:51:18.205117Z","iopub.status.busy":"2024-07-03T11:51:18.204770Z","iopub.status.idle":"2024-07-03T11:51:30.307832Z","shell.execute_reply":"2024-07-03T11:51:30.306760Z","shell.execute_reply.started":"2024-07-03T11:51:18.205089Z"},"id":"XcEKuWIiibpH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import all neccessary modules\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop,Adagrad\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization,Input","metadata":{"id":"8ad1e27a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Preprocessing Image ####","metadata":{"id":"408a93c2"}},{"cell_type":"code","source":"images = []\nlabels = []\nclasses = 43\nfor i in range(classes):\n    path = '/kaggle/working/dataset/train/'+ str(i)\n    raw_images = os.listdir(path)\n    for img in raw_images:\n        try:\n            image = Image.open(path + '/'+ img)\n            image = image.resize((50,50))\n            image = np.array(image)\n            images.append(image)\n            labels.append(i)\n        except Exception as e:\n            print(e)\n\n#converting to numpy array\nimages = np.array(images)\nlabels = np.array(labels)","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:41:33.200787Z","iopub.status.busy":"2024-07-03T12:41:33.200123Z","iopub.status.idle":"2024-07-03T12:41:46.453077Z","shell.execute_reply":"2024-07-03T12:41:46.452205Z","shell.execute_reply.started":"2024-07-03T12:41:33.200756Z"},"id":"83b58071","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = { 0:'Speed limit (20km/h)',\n            1:'Speed limit (30km/h)',\n            2:'Speed limit (50km/h)',\n            3:'Speed limit (60km/h)',\n            4:'Speed limit (70km/h)',\n            5:'Speed limit (80km/h)',\n            6:'End of speed limit (80km/h)',\n            7:'Speed limit (100km/h)',\n            8:'Speed limit (120km/h)',\n            9:'No passing',\n            10:'No passing veh over 3.5 tons',\n            11:'Right-of-way at intersection',\n            12:'Priority road',\n            13:'Yield',\n            14:'Stop',\n            15:'No vehicles',\n            16:'Veh > 3.5 tons prohibited',\n            17:'No entry',\n            18:'General caution',\n            19:'Dangerous curve left',\n            20:'Dangerous curve right',\n            21:'Double curve',\n            22:'Bumpy road',\n            23:'Slippery road',\n            24:'Road narrows on the right',\n            25:'Road work',\n            26:'Traffic signals',\n            27:'Pedestrians',\n            28:'Children crossing',\n            29:'Bicycles crossing',\n            30:'Beware of ice/snow',\n            31:'Wild animals crossing',\n            32:'End speed + passing limits',\n            33:'Turn right ahead',\n            34:'Turn left ahead',\n            35:'Ahead only',\n            36:'Go straight or right',\n            37:'Go straight or left',\n            38:'Keep right',\n            39:'Keep left',\n            40:'Roundabout mandatory',\n            41:'End of no passing',\n            42:'End no passing veh > 3.5 tons' }","metadata":{"id":"7a391b7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape of Image Data: ' + str(images.shape))\nprint('Shape of Label Data: ' + str(labels.shape))","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:42:02.500687Z","iopub.status.busy":"2024-07-03T12:42:02.499816Z","iopub.status.idle":"2024-07-03T12:42:02.505927Z","shell.execute_reply":"2024-07-03T12:42:02.504923Z","shell.execute_reply.started":"2024-07-03T12:42:02.500650Z"},"id":"7adf9500","outputId":"3b002613-aff0-49f9-84b7-1dc480289617","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.25, random_state = 42, shuffle=True)\nprint(\"X_train.shape\", x_train.shape)\nprint(\"X_valid.shape\", x_test.shape)\nprint(\"y_train.shape\", y_train.shape)\nprint(\"y_valid.shape\", y_test.shape)","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:42:06.150724Z","iopub.status.busy":"2024-07-03T12:42:06.150342Z","iopub.status.idle":"2024-07-03T12:42:06.241158Z","shell.execute_reply":"2024-07-03T12:42:06.240188Z","shell.execute_reply.started":"2024-07-03T12:42:06.150694Z"},"id":"070b53b2","outputId":"f099ba31-a892-417f-bbac-9fb3d5b2c5bc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = to_categorical(y_train, 43)\ny_test = to_categorical(y_test, 43)","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:42:13.436826Z","iopub.status.busy":"2024-07-03T12:42:13.436170Z","iopub.status.idle":"2024-07-03T12:42:13.444613Z","shell.execute_reply":"2024-07-03T12:42:13.443352Z","shell.execute_reply.started":"2024-07-03T12:42:13.436791Z"},"id":"50444ca6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Create Model Architecture ####\n","metadata":{"id":"fARq-0PfLuHJ"}},{"cell_type":"code","source":"def create_model():\n  model = Sequential([\n        Input(shape=(50, 50, 3)),\n        Conv2D(filters=16, kernel_size=(8, 8), activation='relu'),\n        Conv2D(filters=32, kernel_size=(8, 8), activation='relu'),\n        MaxPool2D(pool_size=(2, 2)),\n        BatchNormalization(axis=-1),\n        Dropout(rate=0.5),\n        Conv2D(filters=64, kernel_size=(4, 4), activation='relu'),\n        Conv2D(filters=128, kernel_size=(4, 4), activation='relu'),\n        MaxPool2D(pool_size=(2, 2)),\n        BatchNormalization(axis=-1),\n        Dropout(rate=0.5),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(43, activation='softmax')\n    ])\n  return model","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:42:29.122366Z","iopub.status.busy":"2024-07-03T12:42:29.121600Z","iopub.status.idle":"2024-07-03T12:42:29.130764Z","shell.execute_reply":"2024-07-03T12:42:29.129672Z","shell.execute_reply.started":"2024-07-03T12:42:29.122328Z"},"id":"f3f27800","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Creating Model Architecture**","metadata":{"id":"a09UacPUzPhS"}},{"cell_type":"code","source":"model=create_model()\nmodel.summary()","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:42:42.108835Z","iopub.status.busy":"2024-07-03T12:42:42.108464Z","iopub.status.idle":"2024-07-03T12:42:42.786738Z","shell.execute_reply":"2024-07-03T12:42:42.785878Z","shell.execute_reply.started":"2024-07-03T12:42:42.108805Z"},"id":"rkYj70GezE1a","outputId":"2d342498-c658-4d70-911d-cd3bdd5ea2a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Create Checkpoints\nThis is helpfull becuase it saves the learning This approach is beneficial because it saves the model's state after each epoch. This proves invaluable if the training process is interrupted for any reason, as it allows you to resume from the last saved checkpoint rather than starting from scratch","metadata":{"id":"mJSzznz1n2BL"}},{"cell_type":"code","source":"import glob\nimport os\n# from google.colab import drive\n# # Mount Google Drive\n# drive.mount('/content/drive')\n# Set the checkpoint directory to a folder in Google Drive\ncheckpoint_dir = \"/kaggle/working/checkpoints\"\n# Only create the checkpoint directory if it does not exist\nif not os.path.exists(checkpoint_dir):\n    os.makedirs(checkpoint_dir)\nelse:\n    print(\"Checkpoint directory already exists.\")\n# os.makedirs(checkpoint_dir, exist_ok=True)","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:42:58.381253Z","iopub.status.busy":"2024-07-03T12:42:58.380844Z","iopub.status.idle":"2024-07-03T12:42:58.390807Z","shell.execute_reply":"2024-07-03T12:42:58.389807Z","shell.execute_reply.started":"2024-07-03T12:42:58.381224Z"},"id":"T33T_P_4sCqI","outputId":"19e95d76-c4fd-4945-a8e0-b3421658d907","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_latest_checkpoint(name):\n    # Pattern to match checkpoint files for the given optimizer name\n    checkpoint_files = glob.glob(f'{checkpoint_dir}/{name}_epoch*.weights.h5')\n    # If no checkpoint files exist, return None\n    if not checkpoint_files:\n        return None\n    # Find the most recently created checkpoint file\n    latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n    return latest_checkpoint\n\n # Define the checkpoint callback\n\ndef save_checkpoint(name):\n  print(f\"Saving checkpoint for {name} optimizer...\")\n  checkpoint_callback = ModelCheckpoint(\n        filepath=f'{checkpoint_dir}/{name}_epoch{{epoch:02d}}.weights.h5',  # Save each epoch\n        save_weights_only=True,\n        save_freq='epoch',\n        verbose=1\n    )\n  return checkpoint_callback","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:43:09.481508Z","iopub.status.busy":"2024-07-03T12:43:09.480848Z","iopub.status.idle":"2024-07-03T12:43:09.490247Z","shell.execute_reply":"2024-07-03T12:43:09.489314Z","shell.execute_reply.started":"2024-07-03T12:43:09.481475Z"},"id":"bAaMoJpqjd6F","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nepochs=5","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:43:16.719458Z","iopub.status.busy":"2024-07-03T12:43:16.718492Z","iopub.status.idle":"2024-07-03T12:43:16.723630Z","shell.execute_reply":"2024-07-03T12:43:16.722647Z","shell.execute_reply.started":"2024-07-03T12:43:16.719421Z"},"id":"F3HbU5bFpRvu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Part 1 Optimization Algorithms comparision\n\n\n*   Gradient Descent (GD/Batch GD)\n*   Minibatch SGD\n*   Stochastic Gradient Descent\n","metadata":{"id":"OnxfYYKYrWea"}},{"cell_type":"code","source":"# List of optimizers to compare\npart1_optimizers = {\n    'SGD (Batch GD)': SGD(learning_rate=0.01),\n    'SGD (Mini-batch)': SGD(learning_rate=0.01),\n    'SGD (Stochastic)': SGD(learning_rate=0.01)\n}","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:43:25.763086Z","iopub.status.busy":"2024-07-03T12:43:25.762401Z","iopub.status.idle":"2024-07-03T12:43:25.777829Z","shell.execute_reply":"2024-07-03T12:43:25.777096Z","shell.execute_reply.started":"2024-07-03T12:43:25.763054Z"},"id":"M8Z-7CmZlgJc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dictionary to hold accuracy results and histories\npart1_accuracy_results = {}\npart1_histories = {}\n\n# Train and evaluate the model with each optimizer\nfor name, optimizer in part1_optimizers.items():\n    model = create_model()\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n    # Adjust batch size based on optimizer\n    if 'Batch GD' in name:\n        batch_size = len(x_train)  # Entire dataset\n    elif 'Mini-batch' in name:\n        batch_size = 32  # Mini-batch size\n    else:\n        batch_size = 1  # Stochastic (single sample)\n\n    # Load latest checkpoint if it exists\n    latest_checkpoint = get_latest_checkpoint(name)\n    if latest_checkpoint:\n        print(f\"Resuming from checkpoint: {latest_checkpoint}\")\n        model.load_weights(latest_checkpoint)\n\n    print(f\"Training with {name} optimizer...\")\n    # checkpoint callback\n    checkpoint_callback = save_checkpoint(name)\n\n    try:\n        history = model.fit(\n            x_train, y_train,\n            validation_split=0.2,\n            epochs=epochs,\n            batch_size=batch_size,\n            callbacks=[checkpoint_callback],\n            verbose=1\n        )\n        accuracy = model.evaluate(x_test, y_test, verbose=0)[1]\n        part1_accuracy_results[name] = accuracy\n        part1_histories[name] = history.history\n        print(f\"{name} optimizer accuracy: {accuracy}\")\n    except Exception as e:\n        print(f\"Training with {name} optimizer failed due to: {e}\")","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:43:43.413907Z","iopub.status.busy":"2024-07-03T12:43:43.413135Z","iopub.status.idle":"2024-07-03T12:50:10.998891Z","shell.execute_reply":"2024-07-03T12:50:10.997922Z","shell.execute_reply.started":"2024-07-03T12:43:43.413874Z"},"id":"5Soyv5MnF00q","outputId":"599584d0-4feb-4940-b76e-b33dc62db2bc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the results\nprint(\"\\nComparison of Optimizers:\")\nfor name, accuracy in part1_accuracy_results.items():\n    print(f\"{name}: {accuracy}\")\n\npart1_best_optimizer = max(part1_accuracy_results, key=part1_accuracy_results.get)\nprint(f\"\\n Part 1 Best optimizer: {part1_best_optimizer} with accuracy: {part1_accuracy_results[part1_best_optimizer]}\")\n\n# Plotting the training and validation accuracy\nplt.figure(figsize=(14, 6))\nfor name, history in part1_histories.items():\n    plt.plot(history['accuracy'], label=f'{name} Train Accuracy')\n    plt.plot(history['val_accuracy'], label=f'{name} Validation Accuracy')\n\nplt.title('Training and Validation Accuracy for Different Optimizers')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:50:33.456128Z","iopub.status.busy":"2024-07-03T12:50:33.455759Z","iopub.status.idle":"2024-07-03T12:50:33.855256Z","shell.execute_reply":"2024-07-03T12:50:33.854281Z","shell.execute_reply.started":"2024-07-03T12:50:33.456103Z"},"id":"qSEm9NEyHr2R","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Part 2 Optimization Algorithms comparision\n\n\n* Gradient Descent\n* Gradient Descent with Momentum\n* Gradient Descent with Nesterov Momentum\n","metadata":{"id":"PhddOZXMIkvv"}},{"cell_type":"code","source":"part2_optimizers = {\n    'Gradient Descent': SGD(learning_rate=0.01),\n    'Gradient Descent with Momentum': SGD(learning_rate=0.01, momentum=0.9),\n    'Gradient Descent with Nesterov Momentum': SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n    }","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:54:48.844467Z","iopub.status.busy":"2024-07-03T12:54:48.844047Z","iopub.status.idle":"2024-07-03T12:54:48.855747Z","shell.execute_reply":"2024-07-03T12:54:48.854922Z","shell.execute_reply.started":"2024-07-03T12:54:48.844437Z"},"id":"tR9gf4w-IhbJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dictionary to hold accuracy results and histories\npart2_accuracy_results = {}\npart2_histories = {}\n\n# Directory to save checkpoints\ncheckpoint_dir = \"./checkpoints\"\n\n# Train and evaluate the model with each optimizer\nfor name, optimizer in part2_optimizers.items():\n    model = create_model()\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n     # Load latest checkpoint if it exists\n    latest_checkpoint = get_latest_checkpoint(name)\n    if latest_checkpoint:\n        print(f\"Resuming from checkpoint: {latest_checkpoint}\")\n        model.load_weights(latest_checkpoint)\n\n    print(f\"Training with {name} optimizer...\")\n    # checkpoint callback\n    checkpoint_callback = save_checkpoint(name)\n    print(f\"Training with {name} optimizer...\")\n    try:\n        history = model.fit(\n            x_train, y_train,\n            validation_split=0.2,\n            epochs=epochs,\n            batch_size=32,\n            callbacks=[checkpoint_callback],\n            verbose=1\n        )\n        accuracy = model.evaluate(x_test, y_test, verbose=0)[1]\n        part2_accuracy_results[name] = accuracy\n        part2_histories[name] = history.history\n        print(f\"{name} optimizer accuracy: {accuracy}\")\n    except Exception as e:\n        print(f\"Training with {name} optimizer failed due to: {e}\")\n\n# Print the results\nprint(\"\\nComparison of Optimizers:\")\nfor name, accuracy in part2_accuracy_results.items():\n    print(f\"{name}: {accuracy}\")\npart2_best_optimizer = max(part2_accuracy_results, key=part2_accuracy_results.get)\nprint(f\"\\n Part 1 Best optimizer: {part2_best_optimizer} with accuracy: {part2_accuracy_results[part2_best_optimizer]}\")\n\n","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:55:16.659505Z","iopub.status.busy":"2024-07-03T12:55:16.659122Z","iopub.status.idle":"2024-07-03T12:57:07.684254Z","shell.execute_reply":"2024-07-03T12:57:07.683149Z","shell.execute_reply.started":"2024-07-03T12:55:16.659476Z"},"id":"sg43HMKqbrTT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the training and validation accuracy\nplt.figure(figsize=(14, 6))\nfor name, history in part2_histories.items():\n    plt.plot(history['accuracy'], label=f'{name} Train Accuracy')\n    plt.plot(history['val_accuracy'], label=f'{name} Validation Accuracy')\n\nplt.title('Training and Validation Accuracy for Different Optimizers')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:57:40.458936Z","iopub.status.busy":"2024-07-03T12:57:40.457927Z","iopub.status.idle":"2024-07-03T12:57:40.805585Z","shell.execute_reply":"2024-07-03T12:57:40.804637Z","shell.execute_reply.started":"2024-07-03T12:57:40.458887Z"},"id":"3efY8uA0cN5K","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Part 3 Optimization Algorithms comparision\n\n\n*  AdaGrad\n*  RMsProp\n*  Adam\n","metadata":{"id":"uBVVLf86I7En"}},{"cell_type":"code","source":"part3_optimizers = {\n    'Adam': Adam(learning_rate=0.001),\n    'Adagrad': Adagrad(learning_rate=0.01),\n    'RMSprop': RMSprop(learning_rate=0.001)\n}","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:58:12.837814Z","iopub.status.busy":"2024-07-03T12:58:12.837015Z","iopub.status.idle":"2024-07-03T12:58:12.853559Z","shell.execute_reply":"2024-07-03T12:58:12.852696Z","shell.execute_reply.started":"2024-07-03T12:58:12.837779Z"},"id":"_ZzZe6AhI4pU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dictionary to hold accuracy results and histories\npart3_accuracy_results = {}\npart3_histories = {}\n\n# Train and evaluate the model with each optimizer\nfor name, optimizer in part3_optimizers.items():\n    model = create_model()\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n    # Load latest checkpoint if it exists\n    latest_checkpoint = get_latest_checkpoint(name)\n    if latest_checkpoint:\n        print(f\"Resuming from checkpoint: {latest_checkpoint}\")\n        model.load_weights(latest_checkpoint)\n\n    print(f\"Training with {name} optimizer...\")\n    # checkpoint callback\n    checkpoint_callback = save_checkpoint(name)\n\n    print(f\"Training with {name} optimizer...\")\n    try:\n        history = model.fit(\n            x_train, y_train,\n            validation_split=0.2,\n            epochs=epochs,\n            batch_size=32,\n            callbacks=[checkpoint_callback],\n            verbose=1\n        )\n\n        accuracy = model.evaluate(x_test, y_test, verbose=0)[1]\n        part3_accuracy_results[name] = accuracy\n        part3_histories[name] = history.history\n        print(f\"{name} optimizer accuracy: {accuracy}\")\n    except Exception as e:\n        print(f\"Training with {name} optimizer failed due to: {e}\")\n\n# Print the results\nprint(\"\\nComparison of Optimizers:\")\nfor name, accuracy in part3_accuracy_results.items():\n    print(f\"{name}: {accuracy}\")\n\npart3_best_optimizer = max(part3_accuracy_results, key=part3_accuracy_results.get)\nprint(f\"\\nBest optimizer: {part3_best_optimizer} with accuracy: {part3_accuracy_results[part3_best_optimizer]}\")\n","metadata":{"execution":{"iopub.execute_input":"2024-07-03T12:58:24.952437Z","iopub.status.busy":"2024-07-03T12:58:24.951657Z","iopub.status.idle":"2024-07-03T13:00:21.971577Z","shell.execute_reply":"2024-07-03T13:00:21.970584Z","shell.execute_reply.started":"2024-07-03T12:58:24.952400Z"},"id":"70a2ef4f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the training and validation accuracy\nplt.figure(figsize=(14, 6))\nfor name, history in part3_histories.items():\n    plt.plot(history['accuracy'], label=f'{name} Train Accuracy')\n    plt.plot(history['val_accuracy'], label=f'{name} Validation Accuracy')\n\nplt.title('Training and Validation Accuracy for Different Optimizers')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2024-07-03T13:00:48.731745Z","iopub.status.busy":"2024-07-03T13:00:48.731353Z","iopub.status.idle":"2024-07-03T13:00:49.119916Z","shell.execute_reply":"2024-07-03T13:00:49.118974Z","shell.execute_reply.started":"2024-07-03T13:00:48.731714Z"},"id":"cpM52yW5cDPC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install necessary packages\n!pip install pydot\n!pip install graphviz\nfrom tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n# Display the saved image\nImage(filename='model_architecture.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}